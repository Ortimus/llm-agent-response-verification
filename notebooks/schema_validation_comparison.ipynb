{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Schema Validation: Pydantic vs JSON Schema\n",
    "\n",
    "This notebook demonstrates two approaches to validating LLM outputs:\n",
    "1. **Pydantic** - Python-native validation with type coercion and custom validators\n",
    "2. **JSON Schema** - Language-agnostic validation standard\n",
    "\n",
    "Both ensure LLM outputs match expected structure before processing downstream."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Pydantic Validation\n",
    "\n",
    "**Advantages:**\n",
    "- Automatic type coercion (e.g., `\"0.85\"` ‚Üí `0.85`)\n",
    "- Custom field validators for business logic\n",
    "- Better error messages\n",
    "- Native Python integration\n",
    "- Works seamlessly with type hints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import time\n",
    "from pydantic import BaseModel, Field, ValidationError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Pydantic Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvalModel(BaseModel):\n",
    "    \"\"\"Pydantic model for evaluation results.\"\"\"\n",
    "    factual_accuracy: float = Field(ge=0, le=1, description=\"Accuracy score between 0 and 1\")\n",
    "    completeness: float = Field(ge=0, le=1, description=\"Completeness score between 0 and 1\")\n",
    "    clarity: float = Field(ge=0, le=1, description=\"Clarity score between 0 and 1\")\n",
    "    comments: str = Field(min_length=1, description=\"Evaluation comments\")\n",
    "\n",
    "print(\"‚úÖ Pydantic schema defined\")\n",
    "print(\"\\nSchema structure:\")\n",
    "print(json.dumps(EvalModel.model_json_schema(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulated LLM Responses\n",
    "\n",
    "These simulate different failure modes:\n",
    "- Valid JSON with correct types\n",
    "- Valid JSON with wrong types (string instead of float)\n",
    "- Invalid JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulated_llm():\n",
    "    \"\"\"Simulate LLM responses with different failure modes.\"\"\"\n",
    "    choices = [\n",
    "        # Valid response\n",
    "        '{\"factual_accuracy\": 0.85, \"completeness\": 0.8, \"clarity\": 0.9, \"comments\": \"Good.\"}',\n",
    "        \n",
    "        # Type error: string instead of float\n",
    "        '{\"factual_accuracy\": \"high\", \"completeness\": 0.8, \"clarity\": 0.9, \"comments\": \"Ok\"}',\n",
    "        \n",
    "        # Missing required field\n",
    "        '{\"factual_accuracy\": 0.85, \"completeness\": 0.8, \"clarity\": 0.9}',\n",
    "        \n",
    "        # Invalid JSON\n",
    "        'NOT_JSON: error'\n",
    "    ]\n",
    "    return random.choice(choices)\n",
    "\n",
    "print(\"‚úÖ Simulator defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation with Retry Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_with_pydantic(max_retries=3):\n",
    "    \"\"\"Validate LLM output with Pydantic, retrying on failure.\"\"\"\n",
    "    prompt = \"Evaluate the response\"\n",
    "    \n",
    "    for i in range(max_retries):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Attempt {i+1}/{max_retries}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        raw = simulated_llm()\n",
    "        print(f\"Raw LLM output: {raw}\")\n",
    "        \n",
    "        # Try to validate output against schema\n",
    "        try:\n",
    "            data = json.loads(raw)\n",
    "            print(\"‚úÖ Valid JSON\")\n",
    "            \n",
    "            # üß© Convert to Pydantic validated structure\n",
    "            validated = EvalModel(**data)\n",
    "            print(f\"‚úÖ Pydantic validation passed!\")\n",
    "            print(f\"   Validated object: {validated}\")\n",
    "            print(f\"\\n   Access fields as attributes:\")\n",
    "            print(f\"   - Accuracy: {validated.factual_accuracy}\")\n",
    "            print(f\"   - Comments: {validated.comments}\")\n",
    "            return True\n",
    "            \n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"‚ùå Invalid JSON: {e}\")\n",
    "            print(f\"   ‚Üí Would re-prompt: 'Return valid JSON only'\")\n",
    "            \n",
    "        except ValidationError as e:\n",
    "            print(f\"‚ùå Schema Validation Failed:\")\n",
    "            for error in e.errors():\n",
    "                print(f\"   - Field '{error['loc'][0]}': {error['msg']}\")\n",
    "                print(f\"     Type: {error['type']}\")\n",
    "            print(f\"   ‚Üí Would re-prompt with validation feedback\")\n",
    "        \n",
    "        time.sleep(0.1)\n",
    "    \n",
    "    print(f\"\\n‚ùå Failed after {max_retries} attempts\")\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Pydantic Validation Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üöÄ Running Pydantic Validation Demo\\n\")\n",
    "result = validate_with_pydantic(max_retries=5)\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Final Result: {'‚úÖ SUCCESS' if result else '‚ùå FAILED'}\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 2: JSON Schema Validation\n",
    "\n",
    "**Advantages:**\n",
    "- Language-agnostic (works in any language)\n",
    "- Standard specification (RFC 8927)\n",
    "- Portable across systems\n",
    "- Lighter weight (no heavy dependencies)\n",
    "\n",
    "**Disadvantages:**\n",
    "- No automatic type coercion\n",
    "- Less detailed error messages\n",
    "- No custom business logic validators\n",
    "- Requires separate validation library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jsonschema import validate, ValidationError as JSONSchemaValidationError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the JSON Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"factual_accuracy\": {\n",
    "            \"type\": \"number\",\n",
    "            \"minimum\": 0,\n",
    "            \"maximum\": 1,\n",
    "            \"description\": \"Accuracy score between 0 and 1\"\n",
    "        },\n",
    "        \"completeness\": {\n",
    "            \"type\": \"number\",\n",
    "            \"minimum\": 0,\n",
    "            \"maximum\": 1,\n",
    "            \"description\": \"Completeness score between 0 and 1\"\n",
    "        },\n",
    "        \"clarity\": {\n",
    "            \"type\": \"number\",\n",
    "            \"minimum\": 0,\n",
    "            \"maximum\": 1,\n",
    "            \"description\": \"Clarity score between 0 and 1\"\n",
    "        },\n",
    "        \"comments\": {\n",
    "            \"type\": \"string\",\n",
    "            \"minLength\": 1,\n",
    "            \"description\": \"Evaluation comments\"\n",
    "        },\n",
    "    },\n",
    "    \"required\": [\"factual_accuracy\", \"completeness\", \"clarity\", \"comments\"],\n",
    "    \"additionalProperties\": False\n",
    "}\n",
    "\n",
    "print(\"‚úÖ JSON Schema defined\")\n",
    "print(\"\\nSchema structure:\")\n",
    "print(json.dumps(schema, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulated LLM Responses (Same as before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulated_llm_json_schema():\n",
    "    \"\"\"Simulate LLM responses for JSON Schema validation.\"\"\"\n",
    "    choices = [\n",
    "        # Valid response\n",
    "        json.dumps({\n",
    "            \"factual_accuracy\": 0.9,\n",
    "            \"completeness\": 0.81,\n",
    "            \"clarity\": 0.95,\n",
    "            \"comments\": \"ok\"\n",
    "        }),\n",
    "        \n",
    "        # Type error: string instead of number\n",
    "        json.dumps({\n",
    "            \"factual_accuracy\": \"high\",\n",
    "            \"completeness\": 0.8,\n",
    "            \"clarity\": 0.9,\n",
    "            \"comments\": \"good\"\n",
    "        }),\n",
    "        \n",
    "        # Missing required field\n",
    "        json.dumps({\n",
    "            \"factual_accuracy\": 0.85,\n",
    "            \"completeness\": 0.8,\n",
    "            \"clarity\": 0.9\n",
    "        }),\n",
    "        \n",
    "        # Invalid JSON\n",
    "        'NOT_JSON: error'\n",
    "    ]\n",
    "    return random.choice(choices)\n",
    "\n",
    "print(\"‚úÖ Simulator defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation with Retry Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_with_json_schema(max_retries=3):\n",
    "    \"\"\"Validate LLM output with JSON Schema, retrying on failure.\"\"\"\n",
    "    \n",
    "    for i in range(max_retries):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Attempt {i+1}/{max_retries}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        raw = simulated_llm_json_schema()\n",
    "        print(f\"Raw LLM output: {raw}\")\n",
    "        \n",
    "        try:\n",
    "            data = json.loads(raw)\n",
    "            print(\"‚úÖ Valid JSON\")\n",
    "            \n",
    "            # Validate against JSON Schema\n",
    "            validate(instance=data, schema=schema)\n",
    "            print(f\"‚úÖ JSON Schema validation passed!\")\n",
    "            print(f\"   Validated data: {json.dumps(data, indent=2)}\")\n",
    "            print(f\"\\n   Access fields as dict keys:\")\n",
    "            print(f\"   - Accuracy: {data['factual_accuracy']}\")\n",
    "            print(f\"   - Comments: {data['comments']}\")\n",
    "            return True\n",
    "            \n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"‚ùå Invalid JSON: {e}\")\n",
    "            print(f\"   ‚Üí Would re-prompt: 'Return valid JSON only'\")\n",
    "            \n",
    "        except JSONSchemaValidationError as e:\n",
    "            print(f\"‚ùå Schema Validation Failed:\")\n",
    "            print(f\"   Message: {e.message}\")\n",
    "            print(f\"   Failed at path: {list(e.path)}\")\n",
    "            print(f\"   Schema path: {list(e.schema_path)}\")\n",
    "            print(f\"   ‚Üí Would re-prompt with validation feedback\")\n",
    "        \n",
    "        time.sleep(0.1)\n",
    "    \n",
    "    print(f\"\\n‚ùå Failed after {max_retries} attempts\")\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run JSON Schema Validation Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üöÄ Running JSON Schema Validation Demo\\n\")\n",
    "result = validate_with_json_schema(max_retries=5)\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Final Result: {'‚úÖ SUCCESS' if result else '‚ùå FAILED'}\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Comparison Summary\n",
    "\n",
    "| Feature | Pydantic | JSON Schema |\n",
    "|---------|----------|-------------|\n",
    "| **Type Coercion** | ‚úÖ Yes (automatic) | ‚ùå No |\n",
    "| **Error Messages** | ‚úÖ Detailed | ‚ö†Ô∏è Basic |\n",
    "| **Custom Validators** | ‚úÖ Yes | ‚ùå No |\n",
    "| **Language Support** | üêç Python only | üåç Any language |\n",
    "| **Performance** | Fast | Fast |\n",
    "| **Learning Curve** | Moderate | Low |\n",
    "| **Dependencies** | Pydantic package | jsonschema package |\n",
    "| **API Integration** | Python native | Universal |\n",
    "\n",
    "### When to Use What?\n",
    "\n",
    "**Use Pydantic when:**\n",
    "- Building Python-native agents\n",
    "- Need custom business logic validation\n",
    "- Want better error messages for debugging\n",
    "- Working with LangChain or similar frameworks\n",
    "\n",
    "**Use JSON Schema when:**\n",
    "- Need language-agnostic validation\n",
    "- Building polyglot systems\n",
    "- Simple structural validation is sufficient\n",
    "- Want portable validation rules\n",
    "\n",
    "**Pro Tip:** Many production systems use Pydantic during development for better DX, then generate JSON Schema from Pydantic models for API documentation and cross-language compatibility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Generate JSON Schema from Pydantic\n",
    "\n",
    "You can get the best of both worlds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Pydantic model to JSON Schema\n",
    "pydantic_as_json_schema = EvalModel.model_json_schema()\n",
    "\n",
    "print(\"üîÑ Pydantic model as JSON Schema:\")\n",
    "print(json.dumps(pydantic_as_json_schema, indent=2))\n",
    "\n",
    "print(\"\\nüí° This allows you to:\")\n",
    "print(\"   - Develop with Pydantic's rich features\")\n",
    "print(\"   - Export to JSON Schema for API docs\")\n",
    "print(\"   - Share schemas with non-Python services\")\n",
    "print(\"   - Maintain single source of truth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
